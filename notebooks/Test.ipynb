{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/palessandro\n"
     ]
    }
   ],
   "source": [
    "%cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/palessandro/Documents/GitHub/scRNAseq-AAE/src\n"
     ]
    }
   ],
   "source": [
    "%cd Documents/GitHub/scRNAseq-AAE/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "from imp import load_source\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "try:\n",
    "    tf.enable_eager_execution()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tf.executing_eagerly()\n",
    "tf.random.set_seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'latent_dim': 10,\n",
    "    'layers_enc_dim': [200, 100],\n",
    "    'layers_dec_dim': [100, 200],\n",
    "    'layers_dis_dim': [200, 100, 50, 40, 30],\n",
    "    'batch_size': 1000,\n",
    "    'epochs': 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>1000</td>\n",
       "      <td>batch size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>30</td>\n",
       "      <td>number of epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.1</td>\n",
       "      <td>alpha coeff. in activation function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_rate</th>\n",
       "      <td>0.1</td>\n",
       "      <td>dropout rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_initializer</th>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>kernel initializer of all dense layers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_initializer</th>\n",
       "      <td>zeros</td>\n",
       "      <td>bias initializer of all dense layers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>weight of l2 kernel regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>weight of l1 activity regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latent_dim</th>\n",
       "      <td>10</td>\n",
       "      <td>dimension of latent space Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_1_enc_dim</th>\n",
       "      <td>200</td>\n",
       "      <td>dimension of encoder dense layer 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_2_enc_dim</th>\n",
       "      <td>100</td>\n",
       "      <td>dimension of encoder dense layer 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_1_dec_dim</th>\n",
       "      <td>100</td>\n",
       "      <td>dimension of decoder dense layer 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_2_dec_dim</th>\n",
       "      <td>200</td>\n",
       "      <td>dimension of decoder dense layer 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_ae</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>learning rate of autoencoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr_ae</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>decay rate of autoencoder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value                             Description\n",
       "batch_size                    1000                              batch size\n",
       "epochs                          30                        number of epochs\n",
       "alpha                          0.1     alpha coeff. in activation function\n",
       "do_rate                        0.1                            dropout rate\n",
       "kernel_initializer  glorot_uniform  kernel initializer of all dense layers\n",
       "bias_initializer             zeros    bias initializer of all dense layers\n",
       "l2_weight                     None      weight of l2 kernel regularization\n",
       "l1_weight                     None    weight of l1 activity regularization\n",
       "latent_dim                      10             dimension of latent space Z\n",
       "layer_1_enc_dim                200      dimension of encoder dense layer 1\n",
       "layer_2_enc_dim                100      dimension of encoder dense layer 2\n",
       "layer_1_dec_dim                100      dimension of decoder dense layer 1\n",
       "layer_2_dec_dim                200      dimension of decoder dense layer 2\n",
       "lr_ae                       0.0002            learning rate of autoencoder\n",
       "dr_ae                        1e-06               decay rate of autoencoder"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imported.\n"
     ]
    }
   ],
   "source": [
    "model.load_data('../data/proc/pbmc3k.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset rescaled.\n"
     ]
    }
   ],
   "source": [
    "model.rescale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7150213e-01, -2.8281140e-01, -4.9584758e-02, ...,\n",
       "        -1.0294342e-01, -2.0921938e-01, -5.3130406e-01],\n",
       "       [-2.1462303e-01, -3.7560135e-01, -6.4472154e-02, ...,\n",
       "        -2.9296505e-01, -3.1336972e-01, -5.9676743e-01],\n",
       "       [-3.7695917e-01, -2.9723111e-01, -6.9460005e-02, ...,\n",
       "        -1.7101307e-01, -1.7096411e-01,  1.3792611e+00],\n",
       "       ...,\n",
       "       [-2.0712890e-01, -2.5214970e-01, -4.9072269e-02, ...,\n",
       "        -4.9823590e-02, -1.6114253e-01,  2.0418839e+00],\n",
       "       [-1.9036458e-01, -2.2776997e-01, -4.4680536e-02, ...,\n",
       "         1.1567287e-03, -1.3526656e-01, -4.8220244e-01],\n",
       "       [-3.3385262e-01, -2.5530553e-01, -6.0646087e-02, ...,\n",
       "        -8.0574334e-02, -1.3037601e-01, -4.7142717e-01]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 100]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers_enc_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "200\n",
      "2\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for x,y in enumerate(model.layers_enc_dim):\n",
    "    print(x+1)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=model._build_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean=encoder.get_layer('z_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.core.Dense"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = L.Input(shape=(model.original_dim,), name=\"X\")\n",
    "\n",
    "x = encoder_input\n",
    "\n",
    "# add dense layers\n",
    "for i, nodes in enumerate(model.layers_enc_dim):\n",
    "    x = L.Dense(nodes,\n",
    "                name=\"H_\" + str(i + 1),\n",
    "                kernel_initializer=model.kernel_initializer\n",
    "                )(x)\n",
    "\n",
    "    x = L.BatchNormalization(name='BN_' + str(i + 1))(x)\n",
    "\n",
    "    x = L.LeakyReLU(alpha=model.alpha, name='LR_' + str(i + 1))(x)\n",
    "\n",
    "    x = L.Dropout(rate=model.do_rate, name='D_' + str(i + 1))(x)\n",
    "\n",
    "z_mean = L.Dense(model.latent_dim,\n",
    "                 name='z_mean',\n",
    "                 kernel_initializer=model.kernel_initializer,\n",
    "                 bias_initializer=model.bias_initializer)(x)\n",
    "\n",
    "z_log_var = L.Dense(model.latent_dim,\n",
    "                    name='z_log_var',\n",
    "                    kernel_initializer=model.kernel_initializer,\n",
    "                    bias_initializer=model.bias_initializer)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7ff9a8136dd0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape_41:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape(z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.int_shape(z_mean)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(0,), dtype=int32, numpy=array([], dtype=int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape([[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_33:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(z_mean)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 5), dtype=float32, numpy=\n",
       "array([[-0.04601388, -1.2070051 ,  1.4035368 ,  0.585008  ,  1.5661281 ],\n",
       "       [ 0.39359266, -0.15310873, -2.640917  ,  0.0585575 ,  0.47280687],\n",
       "       [-0.28608295,  0.701203  ,  0.66910434,  0.12501723,  0.48414668],\n",
       "       [ 1.33069   ,  1.7339227 , -0.98482805,  0.67556363,  0.21576886],\n",
       "       [-0.7344511 , -0.11199681, -1.2654597 ,  1.5493594 ,  0.509453  ],\n",
       "       [-1.2817936 , -1.0692198 , -1.2472616 , -0.34810218, -0.2199265 ],\n",
       "       [-0.05029231, -0.78237134,  1.1249809 , -0.4487792 ,  0.9772685 ],\n",
       "       [ 0.5371143 , -0.71623814, -0.07685244,  1.2020868 , -1.1730026 ],\n",
       "       [ 1.6985922 , -0.30303127, -0.50709975, -0.5937182 ,  1.6424066 ],\n",
       "       [-0.72944236,  1.3355337 ,  0.69631296,  0.34431094, -0.9916968 ],\n",
       "       [-0.57779926,  0.5668796 ,  1.920081  , -0.01352757,  0.8291644 ],\n",
       "       [-1.5031109 ,  0.05555005,  1.7687721 , -0.13402446, -0.8920586 ],\n",
       "       [ 1.5303826 ,  0.6293708 , -0.37285572, -0.53755164,  1.5282035 ],\n",
       "       [-1.9320511 , -2.1259263 , -1.0605382 ,  1.5918239 ,  1.0613322 ],\n",
       "       [ 1.9476461 ,  0.80075413,  0.13632245,  0.0552927 , -0.32136357],\n",
       "       [ 2.1400325 ,  0.6747836 , -0.37119478,  0.5434867 ,  0.9041585 ],\n",
       "       [ 0.54976666, -0.90252036, -0.23800796, -0.7403952 , -2.517001  ],\n",
       "       [-0.62376255, -0.55359167, -0.3985446 ,  1.0823144 ,  0.8547331 ],\n",
       "       [ 0.5072695 ,  1.5394202 ,  0.6318819 ,  0.32265678,  1.4481243 ],\n",
       "       [-0.59434915, -0.6886845 ,  0.20955825,  0.9607525 , -0.8730533 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.random_normal(shape=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_7:0' shape=(None, 10) dtype=float32>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.random_normal(shape=(K.shape(z_mean)[0],K.int_shape(z_mean)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: tf.Tensor([ 3 10], shape=(2,), dtype=int32)\n",
      "int_shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "x = K.variable(np.eye(3, 10)) \n",
    "\n",
    "print('shape:', K.shape(x))\n",
    "print('int_shape:', K.int_shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: tf.Tensor([3 2], shape=(2,), dtype=int32)\n",
      "int_shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = K.variable(np.eye(3, 2)) \n",
    "\n",
    "print('shape:', K.shape(x))\n",
    "print('int_shape:', K.int_shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.int_shape(x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7ff9a814e8d0>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 13.829188, -38.171467],\n",
       "       [-38.20907 , -68.279106]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(np.array([[1,2],[3,4]]).astype('float32'))\n",
    "y = tf.convert_to_tensor(np.array([[5,6],[7,8]]).astype('float32'))\n",
    "sampling([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-1.5013766,  1.4486619],\n",
       "       [24.68439  , 59.96495  ]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(np.array([[1,2],[3,4]]).astype('float32'))\n",
    "y = tf.convert_to_tensor(np.array([[5,6],[7,8]]).astype('float32'))\n",
    "sampling([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 17.018486 ,  -1.0975046],\n",
       "       [ 33.18102  , -39.631786 ]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "z_mean = tf.convert_to_tensor(np.array([[1,2],[3,4]]).astype('float32'))\n",
    "z_log_var = tf.convert_to_tensor(np.array([[5,6],[7,8]]).astype('float32'))\n",
    "batch = K.shape(z_mean)[0]\n",
    "dim = K.int_shape(z_mean)[1]\n",
    "# by default, random_normal has mean = 0 and std = 1.0\n",
    "epsilon = K.random_normal(shape=(batch, dim),seed=42)\n",
    "z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 17.018486 ,  -1.0975046],\n",
       "       [ 33.18102  , -39.631786 ]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "z_mean = tf.convert_to_tensor(np.array([[1,2],[3,4]]).astype('float32'))\n",
    "z_log_var = tf.convert_to_tensor(np.array([[5,6],[7,8]]).astype('float32'))\n",
    "batch = K.int_shape(z_mean)[0]\n",
    "dim = K.int_shape(z_mean)[1]\n",
    "# by default, random_normal has mean = 0 and std = 1.0\n",
    "epsilon = K.random_normal(shape=(batch, dim),seed=42)\n",
    "z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
